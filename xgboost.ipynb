{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime as dt\n",
    "import scipy.signal as ss\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import group_lasso\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie zbiorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ndzad\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "holidays_events = pd.read_csv(\"https://www.dropbox.com/s/bxyamlpevkiwwoq/holidays_events.csv?dl=1\")\n",
    "holidays_events[\"holiday_type\"] = holidays_events[\"type\"]\n",
    "holidays_events.drop([\"type\"],axis=1,inplace=True)\n",
    "oil = pd.read_csv(\"https://www.dropbox.com/s/l6ln0ztl4m0pw3a/oil.csv?dl=1\",parse_dates=['date'],index_col='date')\n",
    "oil2 = pd.read_csv(\"https://www.dropbox.com/s/l6ln0ztl4m0pw3a/oil.csv?dl=1\")\n",
    "sample_submission = pd.read_csv(\"https://www.dropbox.com/s/68jjl61x6u3klos/sample_submission.csv?dl=1\")\n",
    "stores = pd.read_csv(\"https://www.dropbox.com/s/lcxn6r9bs2exguq/stores.csv?dl=1\")\n",
    "test = pd.read_csv(\"https://www.dropbox.com/s/cvdo1gn7r5lu2uz/test.csv?dl=1\",index_col='id')\n",
    "train = pd.read_csv(\"https://www.dropbox.com/s/s8p2b5awnuqfk0d/train.csv?dl=1\",index_col='id')\n",
    "transactions = pd.read_csv(\"https://www.dropbox.com/s/92fij9bcwt0e0cj/transactions.csv?dl=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja przygotowująca dane objaśniające. Łączy zbiory i zmienia zmienne kategoryczne na zmienne numeryczna metodą One Hot Encoding, a także grupuje po dniu lub miesiącu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def przygotowanie_danych(df: pd.DataFrame, type, type_item):\n",
    "    \"\"\"\n",
    "    Funkcja łącząca zbiory i zmieniająca zmienne kategoryczne na zmienne numeryczne. Funkcja jest przewidziana\n",
    "    df - zbiór danych treningowych\n",
    "    type - dane sklepowe ('family') / dane rodzinne ('store_nbr')\n",
    "    type_item - konretny element zmiennej type np. dla type==\"family\" type_item==\"AUTOMOTIVE\"\n",
    "    \"\"\"\n",
    "    #Łaczymy z pozostałymi zbiorami\n",
    "\n",
    "    #Zbiór stores\n",
    "    df = df.merge(stores,how=\"left\",left_on=['store_nbr'],right_on=['store_nbr'])\n",
    "\n",
    "    #Zbiór transactions\n",
    "    df = df.merge(transactions,how=\"left\",left_on=['date','store_nbr'],right_on=['date','store_nbr'])\n",
    "\n",
    "    #Zbiór holidays_events\n",
    "    df = df.merge(holidays_events,how=\"left\",left_on=['date'],right_on=['date'])\n",
    "\n",
    "    #Dodanie oil\n",
    "    df = df.merge(oil2,how=\"left\",left_on=['date'],right_on=['date'])\n",
    "\n",
    "    #Interpolacja braków danych z oil\n",
    "    df.interpolate(method ='linear', limit_direction ='backward', inplace=True)\n",
    "\n",
    "    #Wybieramy family ze zbioru traningowego\n",
    "    df_fam = df.loc[(df[type]==type_item)]\n",
    "    \n",
    "    #Dodajemy zmienne na dzień tygodnia i na miesiąc\n",
    "    df_fam['dayofweek'] = pd.DatetimeIndex(df_fam['date']).dayofweek + 1\n",
    "    df_fam['month'] = pd.to_datetime(df_fam['date']).dt.month\n",
    "\n",
    "    #Usunięcie zmiennych, które nie będą zmieniane\n",
    "    df_fam.drop([type,\"description\",\"transferred\"],axis=1,inplace=True)\n",
    "    if type == \"family\":\n",
    "        type_opposite = \"store_nbr\"\n",
    "    elif type == \"store_nbr\":\n",
    "        type_opposite = \"family\"\n",
    "\n",
    "    #One Hot Encoding\n",
    "    df_fam = pd.get_dummies(df_fam,columns=[\"locale\",type_opposite,\"city\", \"state\", \"type\", \"cluster\",\"locale_name\", \"holiday_type\"],prefix=[\"locale\",type_opposite,\"city\", \"state\", \"type\", \"cluster\",\"locale_name\", \"holiday_type\"])\n",
    "    \n",
    "    return(df_fam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dane_drzewo(df: pd.DataFrame, type, type_item):\n",
    "    df2 =df.copy()\n",
    "    df2[\"family\"], uniques=pd.factorize(df2[\"family\"])\n",
    "    df2[\"city\"], uniques=pd.factorize(df2[\"city\"])\n",
    "    df2[\"state\"], uniques=pd.factorize(df2[\"state\"])\n",
    "    df2[\"type\"], uniques=pd.factorize(df2[\"type\"])\n",
    "    df2[\"locale\"], uniques=pd.factorize(df2[\"locale\"])\n",
    "    df2[\"locale_name\"], uniques=pd.factorize(df2[\"locale_name\"])\n",
    "    df2[\"holiday_type\"], uniques=pd.factorize(df2[\"holiday_type\"])\n",
    "    df2.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział danych na część treningową i walidacyjną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def podzial(df: pd.DataFrame, date='2016-06-01'):\n",
    "    \"\"\"\n",
    "    Funkcja dzieli zbiór df na cześć treningową i walidacyjną względem date.\n",
    "    \"\"\"\n",
    "    train = df.loc[(df['date']<date)].drop([\"date\"],axis=1)\n",
    "    test = df.loc[(df['date']>=date)].reset_index(drop=True).drop([\"date\"],axis=1)\n",
    "    return(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje modelujące"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_xgb(df1: pd.DataFrame,df2: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Funkcja tworzy model XGBoost na danych df1 i waliduje na danych df2.\n",
    "    \"\"\"\n",
    "    #Zbiory danych treningowy\n",
    "    X = df1.drop(['sales'],axis=1).copy()\n",
    "    Y = df1['sales'].copy()\n",
    "\n",
    "    #Zbiory danych walidacyjnych \n",
    "    X_val = df2.drop(['sales'],axis=1)\n",
    "    Y_val = df2['sales'].copy()\n",
    "\n",
    "    #Dopasowanie modelu\n",
    "    model = xgb.XGBRegressor().fit(X,Y)\n",
    "    Y_pred = model.predict(X_val)\n",
    "\n",
    "    #RMSE - jakość dopasowania\n",
    "    RMSE = mean_squared_error(Y_val,Y_pred,squared=False)\n",
    "    print(RMSE)\n",
    "\n",
    "    return([model, RMSE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model regresji liniowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ols(df1: pd.DataFrame,df2: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Funkcja tworzy model regresji liniowej metodą najmniejszych kwadratów na danych df1 i waliduje na danych df2.\n",
    "    \"\"\"\n",
    "    #Zbiory danych treningowy\n",
    "    X = df1.drop(['sales'],axis=1).copy()\n",
    "    Y = df1['sales'].copy()\n",
    "\n",
    "    #Zbiory danych walidacyjnych \n",
    "    X_val = df2.drop(['sales'],axis=1)\n",
    "    Y_val = df2['sales'].copy()\n",
    "\n",
    "    #Dopasowanie modelu\n",
    "    model = sm.OLS(Y,X).fit()\n",
    "    Y_pred = model.predict(X_val)\n",
    "\n",
    "    #RMSE - jakość dopasowania\n",
    "    RMSE = mean_squared_error(Y_val,Y_pred,squared=False)\n",
    "    print(RMSE)\n",
    "\n",
    "    return([model, RMSE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model drzewa regresyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tree(df1: pd.DataFrame,df2: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Funkcja tworzy model drzewa regresyjnego na danych df1 i waliduje na danych df2.\n",
    "    \"\"\"\n",
    "    #Zbiory danych treningowy\n",
    "    X = df1.drop(['sales'],axis=1).copy()\n",
    "    Y = df1['sales'].copy()\n",
    "\n",
    "    #Zbiory danych walidacyjnych \n",
    "    X_val = df2.drop(['sales'],axis=1)\n",
    "    Y_val = df2['sales'].copy()\n",
    "\n",
    "    #Dopasowanie modelu\n",
    "    model = DecisionTreeRegressor().fit(X,Y)\n",
    "    Y_pred = model.predict(X_val)\n",
    "\n",
    "    #RMSE - jakość dopasowania\n",
    "    RMSE = mean_squared_error(Y_val,Y_pred,squared=False)\n",
    "    print(RMSE)\n",
    "\n",
    "    return([model, RMSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_group_lasso(df1,df2,type):\n",
    "    \"\"\"\n",
    "    Funkcja tworzy model drzewa regresyjnego na danych df1 i waliduje na danych df2.\n",
    "    \"\"\"\n",
    "    #Zbiory danych treningowy\n",
    "    X = df1.drop(['sales'],axis=1).copy()\n",
    "    Y = df1['sales'].copy()\n",
    "\n",
    "    #Zbiory danych walidacyjnych \n",
    "    X_val = df2.drop(['sales'],axis=1)\n",
    "    Y_val = df2['sales'].copy()\n",
    "\n",
    "    #Dopasowanie modelu\n",
    "    model = group_lasso.GroupLasso(groups=[-1,-1, 1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
    "        2,  2,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
    "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
    "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
    "        4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
    "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,\n",
    "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,\n",
    "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
    "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
    "        9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10,-1]).fit(X,Y)\n",
    "    Y_pred = model.predict(X_val)\n",
    "\n",
    "    #RMSE - jakość dopasowania\n",
    "    RMSE = mean_squared_error(Y_val,Y_pred,squared=False)\n",
    "    print(RMSE)\n",
    "\n",
    "    return([model, RMSE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndzad\\AppData\\Local\\Temp/ipykernel_22508/789074995.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fam['dayofweek'] = pd.DatetimeIndex(df_fam['date']).dayofweek + 1\n",
      "C:\\Users\\ndzad\\AppData\\Local\\Temp/ipykernel_22508/789074995.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fam['month'] = pd.to_datetime(df_fam['date']).dt.month\n"
     ]
    }
   ],
   "source": [
    "(train2,test2) = podzial(przygotowanie_danych(train,'family','AUTOMOTIVE'),'2016-06-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model_xgb, RMSE_xgb) = model_xgb(train2,test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndzad\\AppData\\Local\\Temp/ipykernel_22508/789074995.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fam['dayofweek'] = pd.DatetimeIndex(df_fam['date']).dayofweek + 1\n",
      "C:\\Users\\ndzad\\AppData\\Local\\Temp/ipykernel_22508/789074995.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fam['month'] = pd.to_datetime(df_fam['date']).dt.month\n",
      "c:\\Users\\ndzad\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "(train3,test3) = podzial(przygotowanie_danych(train,'store_nbr',1),'2016-06-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211.96339640260342\n"
     ]
    }
   ],
   "source": [
    "(model_xgb, RMSE_xgb) = model_xgb(train3,test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wynik dla pojedynczego sklepu wychodzi dużo gorszy od wyniku dla pojedynczej rodziny, więc dalej przeanalizujemy model XGBoost na wszystkich rodzinach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "families = np.array(train[\"family\"].unique())\n",
    "family_models = []\n",
    "family_RMSEs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndzad\\AppData\\Local\\Temp/ipykernel_22508/789074995.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fam['dayofweek'] = pd.DatetimeIndex(df_fam['date']).dayofweek + 1\n",
      "C:\\Users\\ndzad\\AppData\\Local\\Temp/ipykernel_22508/789074995.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fam['month'] = pd.to_datetime(df_fam['date']).dt.month\n",
      "c:\\Users\\ndzad\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'XGBRegressor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22508/135080759.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfamilies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpodzial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprzygotowanie_danych\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'family'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2016-06-01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mmodel_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSE_xgb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_xgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mfamily_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfamily_RMSEs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRMSE_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'XGBRegressor' object is not callable"
     ]
    }
   ],
   "source": [
    "for i in families:\n",
    "    (train2,test2) = podzial(przygotowanie_danych(train,'family',i),'2016-06-01')\n",
    "    (model_xgb, RMSE_xgb) = model_xgb(train2,test2)\n",
    "    family_models.append(model_xgb)\n",
    "    family_RMSEs.append(RMSE_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Outliery (zrobione)\n",
    "- Grupowanie po family,typie sklep (uśrednienie sprzedaży po dacie)\n",
    "- Agregacja i predykcja na miesiąc "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbce44053a392e2d3acfeeaf9c14acc950329011ff8566e096397dd8c7fd702a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
